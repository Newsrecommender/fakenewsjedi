{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PROJECT IDEA(S)\n",
    "# take ~10000 known fake\n",
    "# take ~10000 known real\n",
    "# combine and take ~25% to put in holdout set - do not use to model - use as verifier of model\n",
    "# feature extraction - \n",
    "# can have 10 different metrics for exclamation marks: \n",
    "# total number of exclamation marks per \n",
    "\n",
    "# look at number of key words: \"outrageous\", \"strong words\"\n",
    "# Q: how strong is the strongest word\n",
    "# unique word count - word frequency\n",
    "# columns: fake / not fake, trustworthiness of source, strength of strongest word found in given article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12999, 19)\n",
      "(422419, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_ind\n",
    "from matplotlib import rcParams\n",
    "\n",
    "fake_df = pd.DataFrame.from_csv(\"fake.csv\")\n",
    "real_df = pd.DataFrame.from_csv(\"../uci-news-aggregator.csv\")\n",
    "\n",
    "fake_num_rows = fake_df.shape\n",
    "print(fake_num_rows)\n",
    "\n",
    "real_num_rows = real_df.shape\n",
    "print(real_num_rows)\n",
    "\n",
    "# df.head(100)\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_df = real_df.head(12999)\n",
    "# print(real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs            11492\n",
      "bias            443\n",
      "conspiracy      430\n",
      "hate            246\n",
      "satire          146\n",
      "state           121\n",
      "junksci         102\n",
      "fake             19\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts_by_type = fake_df['type'].value_counts()\n",
    "print(counts_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_url = fake_df['main_img_url'].value_counts()\n",
    "# print(counts_by_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(fake_df['spam_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_url = fake_df['site_url'].value_counts()\n",
    "# print(counts_by_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_of_spam = fake_df['spam_score'].value_counts()\n",
    "# print(counts_of_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = fake_df.columns.tolist()\n",
    "# print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_replies = fake_df['replies_count'].value_counts()\n",
    "# print(counts_by_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_author = fake_df['author'].value_counts()\n",
    "# print(counts_by_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_domain_rank = fake_df['domain_rank'].value_counts()\n",
    "# print(counts_by_domain_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PROJECT IDEA(S)\n",
    "# take ~10000 known fake\n",
    "# take ~10000 known real\n",
    "# combine and take ~25% to put in holdout set - do not use to model - use as verifier of model\n",
    "# feature extraction - \n",
    "# can have 10 different metrics for exclamation marks: \n",
    "# total number of exclamation marks per \n",
    "# \n",
    "# look at number of key words: \"outrageous\", \"strong words\"\n",
    "# Q: how strong is the strongest word\n",
    "# unique word count - word frequency\n",
    "# columns: fake / not fake, trustworthiness of source, strength of strongest word found in given article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12999, 19)\n"
     ]
    }
   ],
   "source": [
    "# create new \"id\" column in df \n",
    "# reorder column names, setting \"id\" as first column and delete \"uuid\" col \n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "fake_df = fake_df[['site_url', 'domain_rank', 'author', 'published', 'title', 'thread_title', 'text', 'ord_in_thread', 'crawled', 'country', 'language', 'spam_score', 'main_img_url', 'replies_count', 'participants_count', 'likes', 'comments', 'shares', 'type']]\n",
    "print(fake_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count ratio of number of exclamation marks to words in the given string\n",
    "def count_ratio_exclams(string):\n",
    "    exclam = '!'\n",
    "    space = \" \"\n",
    "    num_exclams = string.count(exclam)\n",
    "    num_spaces = string.count(space)\n",
    "    if num_spaces == 0:\n",
    "        return num_exclams\n",
    "    else:\n",
    "        return num_exclams / num_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the ratio of exclams to question marks + periods in the given string\n",
    "def exclam_ratio_text_body(string):\n",
    "    exclam = '!'\n",
    "    period = '.'\n",
    "    question = '?'\n",
    "    num_exclams = string.count(exclam)\n",
    "    num_period = string.count(period)\n",
    "    num_question = string.count(question)\n",
    "    if num_period + num_question == 0:\n",
    "        return num_exclams\n",
    "    return num_exclams / (num_period + num_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12987\n"
     ]
    }
   ],
   "source": [
    "# create new empty column for ratio_exclams_\n",
    "fake_df.assign(ratio_exclam_in_title=0)\n",
    "  \n",
    "# REMOVE ROWS THAT HAVE NAN thread_title\n",
    "\n",
    "fake_df = fake_df[fake_df['thread_title'].notnull()]\n",
    "print(len(fake_df))\n",
    "\n",
    "# correct id labels\n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    thread_title = fake_df.loc[i, 'thread_title']\n",
    "    count = count_ratio_exclams(thread_title)\n",
    "    fake_df.set_value(i, 'ratio_exclam_in_title', count)\n",
    "\n",
    "# counts_by_title_exclams = fake_df.total_exclam_in_title.value_counts()\n",
    "# print(counts_by_title_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12941\n"
     ]
    }
   ],
   "source": [
    "# create new empty column for total_exclam_in_text count\n",
    "fake_df.assign(ratio_exclam_in_text_body=0)\n",
    "  \n",
    "# REMOVE ROWS THAT HAVE NAN thread_title\n",
    "fake_df = fake_df[fake_df['text'].notnull()]\n",
    "print(len(fake_df))\n",
    "\n",
    "# correct id labels\n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    text = fake_df.loc[i, 'text']\n",
    "    count = exclam_ratio_text_body(text)\n",
    "    fake_df.set_value(i, 'ratio_exclam_in_text_body', count)\n",
    "\n",
    "ratio_in_text_body = fake_df.ratio_exclam_in_text_body.value_counts()\n",
    "# print(ratio_in_text_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new empty column for total_exclam_in_text count\n",
    "fake_df.assign(ratio_exclams_in_text=0)\n",
    "\n",
    "# compute the ratio of exclamation marks to other sentence terminating punctionation\n",
    "# and store in column \"ratio_exclams_in_text\"\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    text = fake_df.loc[i, 'text']\n",
    "    count = exclam_ratio_text_body(text)\n",
    "    fake_df.set_value(i, 'ratio_exclams_in_text', count)\n",
    "\n",
    "counts_ratio_exclams = fake_df.ratio_exclams_in_text.value_counts()\n",
    "# print(counts_ratio_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create series of total exclamation counts in each row's title\n",
    "# for index, row in df.iterrows():\n",
    "#     count = count_total_exclamation(row.title)\n",
    "#     print(count)\n",
    "#     df.loc[:,'total_crime'] = df.apply(get_total_crime, axis=1)\n",
    "#     df.loc[index, row.total_exclam_in_title] = count\n",
    "\n",
    "\n",
    "# df.loc[:, 'total_exclam_in_title'] = df.apply(count_total_exclams, axis=1)    \n",
    "# count_title_exclams = df['total_exclam_in_title'].value_counts()\n",
    "# print(count_title_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make  copy of the fake_df containing only the thread_title & site_url\n",
    "sub_fake_df = fake_df[['thread_title', 'site_url']].copy()\n",
    "\n",
    "# replace all carriage returns and tabs with spaces\n",
    "for i in range(1, len(sub_fake_df) + 1):\n",
    "    title = sub_fake_df.loc[i, 'thread_title']\n",
    "    title = title.split(\"\\n\")\n",
    "    title = \" \".join(title)\n",
    "    title = title.split(\"\\t\")\n",
    "    title = \" \".join(title)\n",
    "    sub_fake_df.set_value(i, 'thread_title', title)\n",
    "\n",
    "# replace all carriage returns and tabs with spaces    \n",
    "for i in range(1, len(sub_fake_df) + 1):\n",
    "    url = sub_fake_df.loc[i, 'site_url']\n",
    "    url = url.split(\"\\n\")\n",
    "    url = \" \".join(url)\n",
    "    url = url.split(\"\\t\")\n",
    "    url = \" \".join(url)\n",
    "    sub_fake_df.set_value(i, 'site_url', url)\n",
    "\n",
    "# turn all tabs into spaces\n",
    "# x = \"The bananas are yellow and green\"\n",
    "# x = x.split(\" \")\n",
    "# print(x)\n",
    "# x = \"+\".join(x)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_real_df = real_df[['TITLE', 'URL']].copy()\n",
    "sub_real_df = sub_real_df.head(12941)\n",
    "\n",
    "# correct id labels\n",
    "sub_real_df['id'] = range(1, len(sub_real_df) + 1)\n",
    "sub_real_df = sub_real_df.set_index('id')\n",
    "\n",
    "# replace all carriage returns and tabs with spaces\n",
    "for i in range(1, len(sub_real_df) + 1):\n",
    "    title = sub_real_df.loc[i, 'TITLE']\n",
    "    title = title.split(\"\\n\")\n",
    "    title = \" \".join(title)\n",
    "    title = title.split(\"\\t\")\n",
    "    title = \" \".join(title)\n",
    "    sub_real_df.set_value(i, 'TITLE', title)\n",
    "\n",
    "# replace all carriage returns and tabs with spaces    \n",
    "for i in range(1, len(sub_real_df) + 1):\n",
    "    url = sub_real_df.loc[i, 'URL']\n",
    "    url = url.split(\"\\n\")\n",
    "    url = \" \".join(url)\n",
    "    url = url.split(\"\\t\")\n",
    "    url = \" \".join(url)\n",
    "    sub_real_df.set_value(i, 'URL', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   TITLE  \\\n",
      "id                                                         \n",
      "1      Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
      "2      Re: Why Did Attorney General Loretta Lynch Ple...   \n",
      "3      BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
      "4      PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
      "5      FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
      "6      Hillary Goes Absolutely Berserk On Protester A...   \n",
      "7      BREAKING! NYPD Ready To Make Arrests In Weiner...   \n",
      "8      WOW! WHISTLEBLOWER TELLS CHILLING STORY Of Mas...   \n",
      "9      BREAKING: CLINTON CLEARED...Was This A Coordin...   \n",
      "10     EVIL HILLARY SUPPORTERS Yell \"F*ck Trump\"…Burn...   \n",
      "11     YIKES! HILLARY GOES OFF THE RAILS…Pulls A Howa...   \n",
      "12     SAY GOODBYE! These 23 Hollywood Celebs Threate...   \n",
      "13     NOT KIDDING: Colleges Give Students “Safe Spac...   \n",
      "14     BOOM! MATH SHOWS Trump Would Have Beaten Obama...   \n",
      "15     BOOM! This Is How President Reagan Handled Pro...   \n",
      "16     TRUMP SUPPORTER GOT NUTS On MSNBC Reporter Cov...   \n",
      "17     TOMI LAHREN Has Special Message For Celebritie...   \n",
      "18     #BoycottComedian…ROBERT DENIRO Wanted “To Punc...   \n",
      "19     HE’S NEVER SOLD AN ORIGINAL PAINTING UNTIL NOW...   \n",
      "20     SORRY LIBERALS…You Can Stop With The Petitions...   \n",
      "21     MARK CUBAN: \"In The Event Donald Wins, I Have ...   \n",
      "22     TRUMP SUPPORTER Whose Brutal Beating By Black ...   \n",
      "23     WOW! WHITE Liberals Suggest Blacks Are Too Stu...   \n",
      "24     LOL! BRITISH WIFE Of LIB ACTOR Who Said: “Ther...   \n",
      "25     EPIC! TUCKER CARLSON Demolishes NYC Councilman...   \n",
      "26     FUNNY! SNL’S SOLUTION To Democrat Election Den...   \n",
      "27     DONALD TRUMP Calls Meeting With Press…Dresses ...   \n",
      "28     OOPS! CRYBABY HAMILTON STARS Who Lectured Penc...   \n",
      "29     WHITE TRUMP-BASHING LIB Reprimanded On LIVE CN...   \n",
      "30         BOOM! Kellyanne Conway Shuts Down CNN’s Cuomo   \n",
      "...                                                  ...   \n",
      "25853  US Navy SEALs board tanker hijacked in Libya -...   \n",
      "25854  UPDATE 2-US forces seize tanker carrying oil f...   \n",
      "25855  Norfolk-based destroyer to aid tanker seized b...   \n",
      "25856         US Navy SEALs board rogue Libya oil tanker   \n",
      "25857          U.S. forces seize control of rogue tanker   \n",
      "25858            US Navy SEALs seize fugitive oil tanker   \n",
      "25859  US Navy SEALs board tanker carrying oil from L...   \n",
      "25860  Shades of 'Captain Phillips': Navy SEALS retak...   \n",
      "25861      US Seals take control of rogue Libya oil ship   \n",
      "25862  US Navy SEALs seize stolen Libyan oil tanker h...   \n",
      "25863  Navy SEALs board and take control of oil tanke...   \n",
      "25864  US Special forces take control of rogue Libya ...   \n",
      "25865        Navy SEALs seize control of hijacked tanker   \n",
      "25866  US forces seize tanker carrying oil from Libya...   \n",
      "25867  US Navy Seals take control of rogue Libya oil ...   \n",
      "25868  US Seals take control of rogue Libya oil ship:...   \n",
      "25869  Navy SEALs board mystery tanker Morning Glory ...   \n",
      "25870  US Navy Seals retake hijacked oil tanker off t...   \n",
      "25871   Cyprus: SEALs take oil tanker from Libyan rebels   \n",
      "25872        US Navy Seals seize North Korean oil tanker   \n",
      "25873            Navy Seals board rogue Libya oil tanker   \n",
      "25874  US Navy Seal Commandos Seize North Korea Oil T...   \n",
      "25875  Israeli pair questioned over Pyongyang-bound o...   \n",
      "25876  Navy SEALs Board Oil Tanker Stolen From Libyan...   \n",
      "25877  US Seals take control of rogue Libya ship: Pen...   \n",
      "25878     Navy SEALS take control of hijacked oil tanker   \n",
      "25879  Navy SEALs take control of hijacked Libyan oil...   \n",
      "25880  U.S. Navy SEALs take control of North Korean-f...   \n",
      "25881  Oil tanker heading back to Libya after capture...   \n",
      "25882             US Seals storm 'oil theft' Libyan ship   \n",
      "\n",
      "                                                     URL  TARGET  \n",
      "id                                                                \n",
      "1                                    100percentfedup.com       1  \n",
      "2                                    100percentfedup.com       1  \n",
      "3                                    100percentfedup.com       1  \n",
      "4                                    100percentfedup.com       1  \n",
      "5                                    100percentfedup.com       1  \n",
      "6                                    100percentfedup.com       1  \n",
      "7                                    100percentfedup.com       1  \n",
      "8                                    100percentfedup.com       1  \n",
      "9                                    100percentfedup.com       1  \n",
      "10                                   100percentfedup.com       1  \n",
      "11                                   100percentfedup.com       1  \n",
      "12                                   100percentfedup.com       1  \n",
      "13                                   100percentfedup.com       1  \n",
      "14                                   100percentfedup.com       1  \n",
      "15                                   100percentfedup.com       1  \n",
      "16                                   100percentfedup.com       1  \n",
      "17                                   100percentfedup.com       1  \n",
      "18                                   100percentfedup.com       1  \n",
      "19                                   100percentfedup.com       1  \n",
      "20                                   100percentfedup.com       1  \n",
      "21                                   100percentfedup.com       1  \n",
      "22                                   100percentfedup.com       1  \n",
      "23                                   100percentfedup.com       1  \n",
      "24                                   100percentfedup.com       1  \n",
      "25                                   100percentfedup.com       1  \n",
      "26                                   100percentfedup.com       1  \n",
      "27                                   100percentfedup.com       1  \n",
      "28                                   100percentfedup.com       1  \n",
      "29                                   100percentfedup.com       1  \n",
      "30                                   100percentfedup.com       1  \n",
      "...                                                  ...     ...  \n",
      "25853  http://www.reuters.com/article/2014/03/17/usa-...       0  \n",
      "25854  http://www.reuters.com/article/2014/03/17/usa-...       0  \n",
      "25855  http://hamptonroads.com/2014/03/norfolkbased-d...       0  \n",
      "25856  http://www.aljazeera.com/news/africa/2014/03/u...       0  \n",
      "25857  http://www.ksdk.com/story/news/nation/2014/03/...       0  \n",
      "25858  http://www.latimes.com/world/worldnow/la-fg-wn...       0  \n",
      "25859  http://uk.reuters.com/article/2014/03/17/uk-us...       0  \n",
      "25860  http://www.arktimes.com/ArkansasBlog/archives/...       0  \n",
      "25861  http://www.ptinews.com/news/4509295_-US-Seals-...       0  \n",
      "25862  http://www.allvoices.com/contributed-news/1671...       0  \n",
      "25863  http://www.newser.com/article/a119b55666b54365...       0  \n",
      "25864  http://www.brisbanetimes.com.au/world/us-speci...       0  \n",
      "25865  http://www.abc17news.com/national-news/Navy-SE...       0  \n",
      "25866  http://www.worldbulletin.net/world/131244/us-f...       0  \n",
      "25867  http://news.yahoo.com/us-seals-control-rogue-l...       0  \n",
      "25868  http://www.ptinews.com/news/4509295_US-Seals-t...       0  \n",
      "25869  http://www.washingtonpost.com/news/morning-mix...       0  \n",
      "25870  http://www.rawstory.com/rs/2014/03/17/us-navy-...       0  \n",
      "25871  http://www.politico.com/story/2014/03/cyprus-n...       0  \n",
      "25872  http://voiceofrussia.com/news/2014_03_17/US-Na...       0  \n",
      "25873  http://blouinnews.com/78329/story/navy-seals-b...       0  \n",
      "25874  http://www.ibtimes.co.uk/us-navy-seal-commando...       0  \n",
      "25875  http://www.thestandard.com.hk/breaking_news_de...       0  \n",
      "25876  http://www.huffingtonpost.com/2014/03/17/navy-...       0  \n",
      "25877  http://www.ptinews.com/news/4509045_US-Seals-t...       0  \n",
      "25878  http://www.washingtontimes.com/news/2014/mar/1...       0  \n",
      "25879  http://wtkr.com/2014/03/17/navy-seals-take-con...       0  \n",
      "25880  http://www.dailymail.co.uk/news/article-258257...       0  \n",
      "25881  http://www.libyaherald.com/2014/03/17/oil-tank...       0  \n",
      "25882  http://www.upstreamonline.com/live/article1355...       0  \n",
      "\n",
      "[25882 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# create new column, 'TARGET' with 1 fake and 0 for real\n",
    "sub_fake_df['TARGET'] = 1\n",
    "sub_fake_df = sub_fake_df.rename(columns = {'thread_title':'TITLE', 'site_url':'URL'})\n",
    "sub_real_df['TARGET'] = 0\n",
    "\n",
    "# combine the two dataframes\n",
    "combined_df = sub_fake_df.append(sub_real_df)\n",
    "\n",
    "# reorder the id index of the combined_df set\n",
    "# correct id labels\n",
    "combined_df['id'] = range(1, len(combined_df) + 1)\n",
    "combined_df = combined_df.set_index('id')\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "combined_df = shuffle(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert combined_df into a new TAB DELIMITED csv\n",
    "combined_df.to_csv(\"cleaned_combined_dataset.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create two sets of data: first is TRAINING SET: 75% OF DATA, 25% VALIDATOR via random num generator\n",
    "sampler = np.random.rand(len(combined_df)) < 0.75\n",
    "training_set = combined_df[sampler]\n",
    "test_set = combined_df[~sampler]\n",
    "\n",
    "#print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training_set.to_csv(\"training_set.csv\", sep='\\t', index=False)\n",
    "test_set.to_csv(\"holdout_set.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stem the \"fake news\" data\n",
    "ps = PorterStemmer()\n",
    "fake_blob = {} \n",
    "real_blob = {}\n",
    "for i in range(len(training_set['TARGET'])):\n",
    "    try:\n",
    "        ss8 = str(training_set['TITLE'].iloc[i].encode('utf8'))\n",
    "    except:\n",
    "        ss8 = \"\"\n",
    "    words = word_tokenize(ss8)\n",
    "    x = set()\n",
    "    for w in words:\n",
    "        x.add(ps.stem(w).lower())\n",
    "\n",
    "    # if this is a 'fake' row entry\n",
    "    if training_set['TARGET'].iloc[i] == 1:\n",
    "        for stword in x:\n",
    "            if stword in fake_blob:\n",
    "                fake_blob[stword] = fake_blob[stword] + 1\n",
    "                #print(stword, \" \", fake_blob[stword])\n",
    "            else:\n",
    "                fake_blob.setdefault(stword, 1)\n",
    "                #print(stword,\" \", fake_blob[stword])\n",
    "                \n",
    "    # we found a 'real' row entry\n",
    "    else:\n",
    "        for stword in x:\n",
    "            if stword in real_blob:\n",
    "                real_blob[stword] = real_blob[stword] + 1\n",
    "            else:\n",
    "                real_blob.setdefault(stword, 1)\n",
    "# print(fakeBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # stem the \"real news\" data    \n",
    "# goodBlob = {}\n",
    "# for i in range(len(sub_real_df['TITLE'])):\n",
    "#     try:\n",
    "#         ss8 = str(sub_real_df['TITLE'].iloc[i].encode('utf8'))\n",
    "#     except:\n",
    "#         pass\n",
    "#     words = word_tokenize(ss8)\n",
    "#     x = set()\n",
    "#     for w in words:\n",
    "#         x.add(ps.stem(w).lower())\n",
    "\n",
    "#     for stword in x:\n",
    "#         if stword in goodBlob:\n",
    "#             goodBlob[stword] = goodBlob[stword] + 1\n",
    "#             #print(stword, \" \", goodBlob[stword])\n",
    "#         else:\n",
    "#             goodBlob.setdefault(stword,1)\n",
    "#             #print(stword,\" \", goodBlob[stword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "riskdict = {}\n",
    "for word in fakeBlob:\n",
    "    if word in goodBlob:\n",
    "        count = (fakeBlob[word] + goodBlob[word])\n",
    "    else:\n",
    "        count = fakeBlob[word]\n",
    "    if count >= 10:\n",
    "        riskdict[word] = fakeBlob[word] / count\n",
    "\n",
    "for word in goodBlob:\n",
    "    if word not in fakeBlob and goodBlob[word] > 10:\n",
    "        riskdict[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TITLE', 'URL', 'TARGET', 'fakeaggregate', 'goodaggregate', 'riskword', 'safeword']\n"
     ]
    }
   ],
   "source": [
    "# add four columns to the combined_df: fakeaggregate, goodaggregate, riskword, safeword\n",
    "results_df = combined_df.copy()\n",
    "results_df['fakeaggregate'] = 0\n",
    "results_df['goodaggregate'] = 0\n",
    "results_df['riskword'] = 0\n",
    "results_df['safeword'] = 0\n",
    "print(results_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   TITLE  \\\n",
      "id                                                         \n",
      "2935   Re: Schools All Over America Are Closing On El...   \n",
      "16680  Stacy Keibler Marries In Secret Ceremony, Who'...   \n",
      "4122    Confronting China: an Interview with John Pilger   \n",
      "4992   The US Military lied to thousands of soldiers ...   \n",
      "8513   Progressives Find ‘White Trash’ More Threateni...   \n",
      "10142  So someone HATED this Oasis documentary so muc...   \n",
      "19040  Microsoft hopes Xbox One sales will skyrocket ...   \n",
      "6069   Human Rights Watch: Nigerian Officials Raping ...   \n",
      "23969  Jeopardy Villain Arthur Chu Finally Loses! The...   \n",
      "4107   The War on UNESCO: Al-Aqsa Mosque is Palestini...   \n",
      "5992   Michelle Runs Her Nasty Mouth At Trump, Then K...   \n",
      "19025  Titanfall Free the Frontier Live Action Traile...   \n",
      "8572   Hillary Finally Concedes: “This Is Painful and...   \n",
      "12134  Now That the Presidential-Election Side Show I...   \n",
      "2095   Experts: ISIS is Root of True Islam and Cannot...   \n",
      "3101   Hillary Clinton KNEW 5 years ago Anthony Weine...   \n",
      "7637                                     HACKING ATTACKS   \n",
      "17494           Colorado made $3.5m 'pot' tax in January   \n",
      "24344                     Veronica Mars for the Ignorant   \n",
      "20771  Blood test can predict Alzheimer's disease thr...   \n",
      "6628   US to replace national Anthem with the Benny H...   \n",
      "9595   Teacher Shows Up For Field Trip Drunk; Gets 75...   \n",
      "18227  Early movers: DKS, JCP, DD, M, TGT, TMUS, S & ...   \n",
      "20600  FDA Approves Cefaly: Headband-Like Device to P...   \n",
      "3941        Can't say under God at Hilary speech!?!??!??   \n",
      "24618  Juan Pablo Galavis and Nikki Ferrell update: '...   \n",
      "5521   Legend Art Cashin On A Trump Presidency, The N...   \n",
      "5343   WikiLeaks Report: Obama Admin Discriminated Ag...   \n",
      "16581  Justin Bieber winks, refuses to talk Selena Go...   \n",
      "619    BOMBSHELL! FBI Reopens Investigation on Hillar...   \n",
      "...                                                  ...   \n",
      "12325  PREPARE FOR THE “CREDIBLE” THREATS ON ELECTION...   \n",
      "3227   Comment on Someone tampered with a Virginia ro...   \n",
      "5767    Final Thoughts on the U.S. Presidential Election   \n",
      "9194   Budgies demand to be released from weird peopl...   \n",
      "24832  Prosecutors oppose McDonnell bid for more details   \n",
      "9413   Book burning for a digital age. Google CEO tal...   \n",
      "23276  This list is brought to you by 25 years of the...   \n",
      "16412         Justin Bieber defends deposition behaviour   \n",
      "6663   NOT OVER: FBI To Conduct New Investigation Of ...   \n",
      "11056  Five Terrifying Things From Trump's Blueprint ...   \n",
      "18490            Twitter restored after 'service outage'   \n",
      "20744  How a “90% accurate” Alzheimer's test can be w...   \n",
      "7575                  Condell: America’s Moment Of Truth   \n",
      "17577                               Retailers Warn On Q1   \n",
      "10794  Actor Mark Ruffalo Joins Activists In ND To Pr...   \n",
      "12603  'Grand slam!' Father-son film is smash hit for...   \n",
      "10780  History Is Made: Physicists Prove Einstein’s T...   \n",
      "659       Putin grants Steven Seagal Russian citizenship   \n",
      "3732                            The Anti-Police Epidemic   \n",
      "17717                Stocks dip on gloomy data from Asia   \n",
      "14362               Nexus 8 to have Intel chip on board?   \n",
      "101    Trump Advocates the American People's Control ...   \n",
      "25028  SCCA experts develop helpful tool to simplify ...   \n",
      "17893  Mark Carney faces MPs over forex fixing invest...   \n",
      "19420  Noah Trailer: Hilarious Emma Watson Introduction!   \n",
      "10759  A Solution For Blindness: World’s First Bionic...   \n",
      "21938  Herbalife Ltd. (HLF) Probe Earns Bill Ackman B...   \n",
      "18381                                      Business Wire   \n",
      "5391   Turkey’s Operation Euphrates Shield is Shieldi...   \n",
      "0                                                    NaN   \n",
      "\n",
      "                                                     URL  TARGET  \\\n",
      "id                                                                 \n",
      "2935                           endoftheamericandream.com     1.0   \n",
      "16680  http://www.inquisitr.com/1165061/stacy-keibler...     0.0   \n",
      "4122                                  greanvillepost.com     1.0   \n",
      "4992                                      intellihub.com     1.0   \n",
      "8513                                  shiftfrequency.com     1.0   \n",
      "10142                                      thepoke.co.uk     1.0   \n",
      "19040  http://tech.firstpost.com/news-analysis/micros...     0.0   \n",
      "6069                                   mintpressnews.com     1.0   \n",
      "23969  http://thesop.org/story/20140313/jeopardy-vill...     0.0   \n",
      "4107                                  greanvillepost.com     1.0   \n",
      "5992                                    madworldnews.com     1.0   \n",
      "19025  http://www.geeky-gadgets.com/titanfall-free-th...     0.0   \n",
      "8572                                        shtfplan.com     1.0   \n",
      "12134                                washingtonsblog.com     1.0   \n",
      "2095                                    dailysquib.co.uk     1.0   \n",
      "3101                                         eutimes.net     1.0   \n",
      "7637                                    prisonplanet.com     1.0   \n",
      "17494  http://manilastandardtoday.com/2014/03/11/colo...     0.0   \n",
      "24344  http://www.thestranger.com/seattle/i-love-tele...     0.0   \n",
      "20771  http://www.mcknights.com/blood-test-can-predic...     0.0   \n",
      "6628                                       newsthump.com     1.0   \n",
      "9595                             thefederalistpapers.org     1.0   \n",
      "18227                   http://www.cnbc.com/id/101483246     0.0   \n",
      "20600  http://www.eurweb.com/2014/03/fda-approves-cef...     0.0   \n",
      "3941                              godlikeproductions.com     1.0   \n",
      "24618  http://www.allvoices.com/contributed-news/1669...     0.0   \n",
      "5521                                   kingworldnews.com     1.0   \n",
      "5343                                      jewsnews.co.il     1.0   \n",
      "16581  http://popwatch.ew.com/2014/03/10/justin-biebe...     0.0   \n",
      "619                                        amtvmedia.com     1.0   \n",
      "...                                                  ...     ...   \n",
      "12325                                    wearechange.org     1.0   \n",
      "3227                            fellowshipoftheminds.com     1.0   \n",
      "5767                               libertyblitzkrieg.com     1.0   \n",
      "9194                                  thedailymash.co.uk     1.0   \n",
      "24832  http://www.appeal-democrat.com/news/national/p...     0.0   \n",
      "9413                                        theduran.com     1.0   \n",
      "23276  http://www.engadget.com/2014/03/12/25-years-of...     0.0   \n",
      "16412  http://www.digitalspy.co.uk/showbiz/news/a5567...     0.0   \n",
      "6663                                 nowtheendbegins.com     1.0   \n",
      "11056                                      truth-out.org     1.0   \n",
      "18490  http://www.indiablooms.com/NewsDetailsPage/201...     0.0   \n",
      "20744  http://ampp3d.mirror.co.uk/2014/03/11/how-a-90...     0.0   \n",
      "7575                                    prisonplanet.com     1.0   \n",
      "17577  http://news.investors.com/business/031114-6928...     0.0   \n",
      "10794                                   trueactivist.com     1.0   \n",
      "12603                                            wnd.com     1.0   \n",
      "10780                                    topinfopost.com     1.0   \n",
      "659                                        amtvmedia.com     1.0   \n",
      "3732                                    frontpagemag.com     1.0   \n",
      "17717  http://triblive.com/business/headlines/5739970...     0.0   \n",
      "14362  http://www.androidpit.com/nexus-8-to-have-inte...     0.0   \n",
      "101                                       abeldanger.net     1.0   \n",
      "25028  http://www.news-medical.net/news/20140311/SCCA...     0.0   \n",
      "17893  http://www.standard.co.uk/business/business-ne...     0.0   \n",
      "19420  http://www.moviefanatic.com/2014/03/noah-trail...     0.0   \n",
      "10759                                    topinfopost.com     1.0   \n",
      "21938  http://www.valuewalk.com/2014/03/herbalife-ltd...     0.0   \n",
      "18381  http://www.virtual-strategy.com/2014/03/11/sof...     0.0   \n",
      "5391                                     journal-neo.org     1.0   \n",
      "0                                                    NaN     NaN   \n",
      "\n",
      "       fakeaggregate  goodaggregate  riskword  safeword  \n",
      "id                                                       \n",
      "2935         12791.0        11551.0  0.635347  0.000000  \n",
      "16680        18358.0        24649.0  0.243243  0.000000  \n",
      "4122         18431.0        23644.0  0.516287  0.000000  \n",
      "4992         16054.0        12915.0  1.000000  0.489417  \n",
      "8513         21898.0        24243.0  1.000000  0.192084  \n",
      "10142        16259.0        14722.0  0.003802  0.000000  \n",
      "19040         2958.0        11734.0  0.187500  0.034722  \n",
      "6069         21616.0        27039.0  0.516287  0.000000  \n",
      "23969         6071.0        15523.0  0.170330  0.000000  \n",
      "4107         15563.0        12807.0  1.000000  0.235849  \n",
      "5992         21279.0        24927.0  0.983425  0.192084  \n",
      "19025        15827.0        12838.0  0.686275  0.253333  \n",
      "8572         12888.0        11500.0  0.500000  0.138776  \n",
      "12134        19854.0        24313.0  0.626866  0.000000  \n",
      "2095         15611.0        15852.0  0.516287  0.039935  \n",
      "3101         17821.0        13861.0  1.000000  0.517730  \n",
      "7637         20956.0        17051.0  0.516287  0.000000  \n",
      "17494        22833.0        19290.0  0.567273  0.034884  \n",
      "24344        13875.0        11943.0  0.103896  0.103896  \n",
      "20771        16179.0        14971.0  0.418931  0.000000  \n",
      "6628         20886.0        17188.0  1.000000  0.489417  \n",
      "9595         16409.0        14982.0  0.768707  0.425000  \n",
      "18227        16114.0        13697.0  1.000000  0.489417  \n",
      "20600        17068.0        24617.0  0.217849  0.000000  \n",
      "3941         15691.0        13888.0  0.516287  0.146341  \n",
      "24618        14464.0        12779.0  0.302885  0.000000  \n",
      "5521          3019.0        12395.0  0.529412  0.000000  \n",
      "5343         15580.0        13747.0  0.602941  0.285714  \n",
      "16581        17467.0        14090.0  0.418931  0.418931  \n",
      "619          17139.0        14717.0  0.302885  0.000000  \n",
      "...              ...            ...       ...       ...  \n",
      "12325         8728.0        14515.0  0.514286  0.192084  \n",
      "3227         18028.0        23513.0  0.623656  0.000000  \n",
      "5767         23006.0        19406.0  0.019886  0.000000  \n",
      "9194         16073.0        14296.0  0.516287  0.078571  \n",
      "24832        12456.0        11252.0  0.359551  0.000000  \n",
      "9413         18388.0        15442.0  0.958333  0.493894  \n",
      "23276        15766.0        13576.0  1.000000  0.133333  \n",
      "16412        17865.0        16125.0  0.240453  0.026667  \n",
      "6663         21551.0        27145.0  0.465409  0.002342  \n",
      "11056        13901.0        12112.0  0.534470  0.375000  \n",
      "18490        21165.0        16606.0  0.673077  0.335616  \n",
      "20744        18698.0        14510.0  0.534470  0.534093  \n",
      "7575         16108.0        12658.0  0.696589  0.534093  \n",
      "17577        15638.0        22341.0  0.456790  0.000000  \n",
      "10794        15747.0        12694.0  0.654135  0.235849  \n",
      "12603        15520.0        14083.0  0.554556  0.000000  \n",
      "10780        16605.0        14573.0  0.418931  0.384615  \n",
      "659          18558.0        16322.0  0.090909  0.090909  \n",
      "3732         18507.0        17442.0  0.764192  0.010753  \n",
      "17717        17074.0        22213.0  0.496711  0.000000  \n",
      "14362        18771.0        14699.0  0.253205  0.253205  \n",
      "101          19398.0        24436.0  0.202020  0.041379  \n",
      "25028        19387.0        24963.0  0.516287  0.000000  \n",
      "17893        13841.0        12513.0  0.534093  0.461656  \n",
      "19420        20197.0        24864.0  0.516287  0.192084  \n",
      "10759        14318.0        11695.0  0.696589  0.084746  \n",
      "21938        29509.0        23449.0  0.516287  0.312500  \n",
      "18381        14018.0        11686.0  1.000000  0.534093  \n",
      "5391         19184.0        15352.0  0.555556  0.516287  \n",
      "0            25085.0        19766.0  0.764192  0.463415  \n",
      "\n",
      "[25883 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "riskword = \"\"\n",
    "for i in range(len(_df['TITLE'])):\n",
    "    fakeaggregate = 0\n",
    "    goodaggregate = 0\n",
    "    riskyword = 0\n",
    "    safeword = 1\n",
    "    try:\n",
    "        ss8 = str(results_df['TITLE'].iloc[i].encode('utf8'))\n",
    "    except:\n",
    "        pass\n",
    "    words = word_tokenize(ss8)\n",
    "    x = set()\n",
    "    for w in words:\n",
    "        x.add(ps.stem(w).lower())\n",
    "\n",
    "    for stword in x:\n",
    "        if stword in riskdict:\n",
    "            if riskdict[stword] > riskyword:\n",
    "                riskword = riskdict[stword]\n",
    "            if riskdict[stword] < safeword:\n",
    "                safeword = riskdict[stword]\n",
    "\n",
    "        if stword in fakeBlob:\n",
    "            fakeaggregate = fakeBlob[stword] + fakeaggregate\n",
    "\n",
    "        if stword in goodBlob:\n",
    "            goodaggregate = goodBlob[stword] + goodaggregate\n",
    "    results_df.set_value(i, 'fakeaggregate', fakeaggregate)\n",
    "    results_df.set_value(i, 'goodaggregate', goodaggregate)\n",
    "    results_df.set_value(i, 'riskword', riskword)\n",
    "    results_df.set_value(i, 'safeword', safeword)\n",
    "    \n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
