{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12999, 19)\n",
      "(422419, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_ind\n",
    "from matplotlib import rcParams\n",
    "\n",
    "fake_df = pd.DataFrame.from_csv(\"fake.csv\")\n",
    "real_df = pd.DataFrame.from_csv(\"../uci-news-aggregator.csv\")\n",
    "\n",
    "fake_num_rows = fake_df.shape\n",
    "print(fake_num_rows)\n",
    "\n",
    "real_num_rows = real_df.shape\n",
    "print(real_num_rows)\n",
    "\n",
    "# df.head(100)\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_df = real_df.head(12999)\n",
    "# print(real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs            11492\n",
      "bias            443\n",
      "conspiracy      430\n",
      "hate            246\n",
      "satire          146\n",
      "state           121\n",
      "junksci         102\n",
      "fake             19\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts_by_type = fake_df['type'].value_counts()\n",
    "print(counts_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_url = fake_df['main_img_url'].value_counts()\n",
    "# print(counts_by_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(fake_df['spam_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_url = fake_df['site_url'].value_counts()\n",
    "# print(counts_by_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_of_spam = fake_df['spam_score'].value_counts()\n",
    "# print(counts_of_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = fake_df.columns.tolist()\n",
    "# print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_replies = fake_df['replies_count'].value_counts()\n",
    "# print(counts_by_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_author = fake_df['author'].value_counts()\n",
    "# print(counts_by_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_domain_rank = fake_df['domain_rank'].value_counts()\n",
    "# print(counts_by_domain_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PROJECT IDEA(S)\n",
    "# take ~10000 known fake\n",
    "# take ~10000 known real\n",
    "# combine and take ~25% to put in holdout set - do not use to model - use as verifier of model\n",
    "# feature extraction - \n",
    "# can have 10 different metrics for exclamation marks: \n",
    "# total number of exclamation marks per \n",
    "# \n",
    "# look at number of key words: \"outrageous\", \"strong words\"\n",
    "# Q: how strong is the strongest word\n",
    "# unique word count - word frequency\n",
    "# columns: fake / not fake, trustworthiness of source, strength of strongest word found in given article, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12999, 19)\n"
     ]
    }
   ],
   "source": [
    "# create new \"id\" column in df \n",
    "# reorder column names, setting \"id\" as first column and delete \"uuid\" col \n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "fake_df = fake_df[['site_url', 'domain_rank', 'author', 'published', 'title', 'thread_title', 'text', 'ord_in_thread', 'crawled', 'country', 'language', 'spam_score', 'main_img_url', 'replies_count', 'participants_count', 'likes', 'comments', 'shares', 'type']]\n",
    "print(fake_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count total number of exclamation marks in the given string\n",
    "def count_total_exclams(string):\n",
    "    exclam = '!'\n",
    "    num_exclams = string.count(exclam)\n",
    "    return num_exclams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the ratio of exclams to question marks + periods in the given string\n",
    "def exclam_ratio(string):\n",
    "    exclam = '!'\n",
    "    period = '.'\n",
    "    question = '?'\n",
    "    num_exclams = string.count(exclam)\n",
    "    num_period = string.count(period)\n",
    "    num_question = string.count(question)\n",
    "    if num_period + num_question == 0:\n",
    "        return num_exclams\n",
    "    return num_exclams / (num_period + num_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12987\n"
     ]
    }
   ],
   "source": [
    "# create new empty column for total_exclam_in_title count\n",
    "fake_df.assign(total_exclam_in_title=0)\n",
    "  \n",
    "# REMOVE ROWS THAT HAVE NAN thread_title\n",
    "\n",
    "fake_df = fake_df[fake_df['thread_title'].notnull()]\n",
    "print(len(fake_df))\n",
    "\n",
    "# correct id labels\n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    #title = fake_df.loc[i, 'title']\n",
    "    thread_title = fake_df.loc[i, 'thread_title']\n",
    "    count = count_total_exclams(thread_title)\n",
    "    fake_df.set_value(i, 'total_exclam_in_title', count)\n",
    "\n",
    "counts_by_title_exclams = fake_df.total_exclam_in_title.value_counts()\n",
    "# print(counts_by_title_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12941\n"
     ]
    }
   ],
   "source": [
    "# create new empty column for total_exclam_in_text count\n",
    "fake_df.assign(total_exclam_in_text=0)\n",
    "  \n",
    "# REMOVE ROWS THAT HAVE NAN thread_title\n",
    "fake_df = fake_df[fake_df['text'].notnull()]\n",
    "print(len(fake_df))\n",
    "\n",
    "# correct id labels\n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    text = fake_df.loc[i, 'text']\n",
    "    count = count_total_exclams(text)\n",
    "    fake_df.set_value(i, 'total_exclam_in_text', count)\n",
    "\n",
    "counts_by_text_exclams = fake_df.total_exclam_in_text.value_counts()\n",
    "# print(counts_by_text_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new empty column for total_exclam_in_text count\n",
    "fake_df.assign(ratio_exclams_in_text=0)\n",
    "\n",
    "# compute the ratio of exclamation marks to other sentence terminating punctionation\n",
    "# and store in column \"ratio_exclams_in_text\"\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    text = fake_df.loc[i, 'text']\n",
    "    count = exclam_ratio(text)\n",
    "    fake_df.set_value(i, 'ratio_exclams_in_text', count)\n",
    "\n",
    "counts_ratio_exclams = fake_df.ratio_exclams_in_text.value_counts()\n",
    "# print(counts_ratio_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create series of total exclamation counts in each row's title\n",
    "# for index, row in df.iterrows():\n",
    "#     count = count_total_exclamation(row.title)\n",
    "#     print(count)\n",
    "#     df.loc[:,'total_crime'] = df.apply(get_total_crime, axis=1)\n",
    "#     df.loc[index, row.total_exclam_in_title] = count\n",
    "\n",
    "\n",
    "# df.loc[:, 'total_exclam_in_title'] = df.apply(count_total_exclams, axis=1)    \n",
    "# count_title_exclams = df['total_exclam_in_title'].value_counts()\n",
    "# print(count_title_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make  copy of the fake_df containing only the thread_title & site_url\n",
    "sub_fake_df = fake_df[['thread_title', 'site_url']].copy()\n",
    "\n",
    "# replace all carriage returns and tabs with spaces\n",
    "for i in range(1, len(sub_fake_df) + 1):\n",
    "    title = sub_fake_df.loc[i, 'thread_title']\n",
    "    title = title.split(\"\\n\")\n",
    "    title = \" \".join(title)\n",
    "    title = title.split(\"\\t\")\n",
    "    title = \" \".join(title)\n",
    "    sub_fake_df.set_value(i, 'thread_title', title)\n",
    "\n",
    "# replace all carriage returns and tabs with spaces    \n",
    "for i in range(1, len(sub_fake_df) + 1):\n",
    "    url = sub_fake_df.loc[i, 'site_url']\n",
    "    url = url.split(\"\\n\")\n",
    "    url = \" \".join(url)\n",
    "    url = url.split(\"\\t\")\n",
    "    url = \" \".join(url)\n",
    "    sub_fake_df.set_value(i, 'site_url', url)\n",
    "    \n",
    "# print(sub_fake_df)\n",
    "\n",
    "# turn all tabs into spaces\n",
    "# x = \"The bananas are yellow and green\"\n",
    "# x = x.split(\" \")\n",
    "# print(x)\n",
    "# x = \"+\".join(x)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_real_df = real_df[['TITLE', 'URL']].copy()\n",
    "sub_real_df = sub_real_df.head(12941)\n",
    "\n",
    "# correct id labels\n",
    "sub_real_df['id'] = range(1, len(sub_real_df) + 1)\n",
    "sub_real_df = sub_real_df.set_index('id')\n",
    "\n",
    "# replace all carriage returns and tabs with spaces\n",
    "for i in range(1, len(sub_real_df) + 1):\n",
    "    title = sub_real_df.loc[i, 'TITLE']\n",
    "    title = title.split(\"\\n\")\n",
    "    title = \" \".join(title)\n",
    "    title = title.split(\"\\t\")\n",
    "    title = \" \".join(title)\n",
    "    sub_real_df.set_value(i, 'TITLE', title)\n",
    "\n",
    "# replace all carriage returns and tabs with spaces    \n",
    "for i in range(1, len(sub_real_df) + 1):\n",
    "    url = sub_real_df.loc[i, 'URL']\n",
    "    url = url.split(\"\\n\")\n",
    "    url = \" \".join(url)\n",
    "    url = url.split(\"\\t\")\n",
    "    url = \" \".join(url)\n",
    "    sub_real_df.set_value(i, 'URL', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new column, 'TARGET' with 1 fake and 0 for real\n",
    "sub_fake_df['TARGET'] = 1\n",
    "sub_fake_df = sub_fake_df.rename(columns = {'thread_title':'TITLE', 'site_url':'URL'})\n",
    "sub_real_df['TARGET'] = 0\n",
    "\n",
    "# combine the two dataframes\n",
    "combined_df = sub_fake_df.append(sub_real_df)\n",
    "# print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert combined_df into a new TAB DELIMITED csv\n",
    "combined_df.to_csv(\"cleaned_combined_dataset.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'rais': 1, b'4': 1, b'$': 1, b'ipo': 1, b'compani': 1, b'up': 1, b'40': 1, b'in': 1, b'as': 1, b\"'\": 1, b'billion': 1, b'much': 1, b'to': 1, b',': 1, b\"b'snapchat\": 1, b'valu': 1}\n"
     ]
    }
   ],
   "source": [
    "# stem the \"fake news\" data\n",
    "ps = PorterStemmer()\n",
    "fakeBlob = {} \n",
    "ss8 = str() \n",
    "for i in range(len(sub_fake_df['TITLE'])):\n",
    "    try:\n",
    "        ss8 = str(sub_fake_df['TITLE'].iloc[i].encode('utf8'))\n",
    "    except:\n",
    "        pass\n",
    "    #print(sub_fake_df['thread_title'].iloc[i])\n",
    "    words = word_tokenize(ss8)\n",
    "    x = set()\n",
    "    for w in words:\n",
    "        x.add(w)\n",
    "\n",
    "for w in x:\n",
    "    stwordcase = ps.stem(w).encode('utf-8')\n",
    "    stword = stwordcase.lower()\n",
    "    if stword in fakeBlob:\n",
    "        fakeBlob[stword] = fakeBlob[stword] + 1\n",
    "        # print(stword,  fakeBlob[stword])\n",
    "    else:\n",
    "        fakeBlob.setdefault(stword,1)\n",
    "        # print(stword, fakeBlob[stword])\n",
    "\n",
    "print(fakeBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'seal': 1, b'theft': 1, b'ship': 1, b\"''\": 1, b\"'\": 1, b'b': 1, b'us': 1, b\"'oil\": 1, b'libyan': 1, b'storm': 1}\n"
     ]
    }
   ],
   "source": [
    "# stem the \"real news\" data\n",
    "ps = PorterStemmer()\n",
    "realBlob = {} \n",
    "ss8 = str() \n",
    "for i in range(len(sub_real_df['TITLE'])):\n",
    "    try:\n",
    "        ss8 = str(sub_real_df['TITLE'].iloc[i].encode('utf8'))\n",
    "    except:\n",
    "        pass\n",
    "    #print(sub_fake_df['thread_title'].iloc[i])\n",
    "    words = word_tokenize(ss8)\n",
    "    x = set()\n",
    "    for w in words:\n",
    "        x.add(w)\n",
    "\n",
    "for w in x:\n",
    "    stwordcase = ps.stem(w).encode('utf-8')\n",
    "    stword = stwordcase.lower()\n",
    "    if stword in realBlob:\n",
    "        realBlob[stword] = realBlob[stword] + 1\n",
    "        # print(stword,  realBlob[stword])\n",
    "    else:\n",
    "        realBlob.setdefault(stword,1)\n",
    "        # print(stword, realBlob[stword])\n",
    "\n",
    "print(realBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create two sets of data: first is TRAINING SET: 75% OF DATA, 25% VALIDATOR\n",
    "# using a random num generator \n",
    "sampler = np.random.rand(len(combined_df)) < 0.75\n",
    "training_set = combined_df[sampler]\n",
    "print(training_set)\n",
    "\n",
    "test_set = combined_df[~sampler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
