{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PROJECT IDEA(S)\n",
    "# take ~10000 known fake\n",
    "# take ~10000 known real\n",
    "# combine and take ~25% to put in holdout set - do not use to model - use as verifier of model\n",
    "# feature extraction - \n",
    "# can have 10 different metrics for exclamation marks: \n",
    "# total number of exclamation marks per \n",
    "\n",
    "# look at number of key words: \"outrageous\", \"strong words\"\n",
    "# Q: how strong is the strongest word\n",
    "# unique word count - word frequency\n",
    "# columns: fake / not fake, trustworthiness of source, strength of strongest word found in given article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12999, 19)\n",
      "(422419, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_ind\n",
    "from matplotlib import rcParams\n",
    "\n",
    "fake_df = pd.DataFrame.from_csv(\"fake.csv\")\n",
    "real_df = pd.DataFrame.from_csv(\"../uci-news-aggregator.csv\")\n",
    "\n",
    "fake_num_rows = fake_df.shape\n",
    "print(fake_num_rows)\n",
    "\n",
    "real_num_rows = real_df.shape\n",
    "print(real_num_rows)\n",
    "\n",
    "# df.head(100)\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_df = real_df.head(12999)\n",
    "# print(real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs            11492\n",
      "bias            443\n",
      "conspiracy      430\n",
      "hate            246\n",
      "satire          146\n",
      "state           121\n",
      "junksci         102\n",
      "fake             19\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts_by_type = fake_df['type'].value_counts()\n",
    "print(counts_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_url = fake_df['main_img_url'].value_counts()\n",
    "# print(counts_by_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(fake_df['spam_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_url = fake_df['site_url'].value_counts()\n",
    "# print(counts_by_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_of_spam = fake_df['spam_score'].value_counts()\n",
    "# print(counts_of_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = fake_df.columns.tolist()\n",
    "# print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_replies = fake_df['replies_count'].value_counts()\n",
    "# print(counts_by_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_author = fake_df['author'].value_counts()\n",
    "# print(counts_by_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_domain_rank = fake_df['domain_rank'].value_counts()\n",
    "# print(counts_by_domain_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PROJECT IDEA(S)\n",
    "# take ~10000 known fake\n",
    "# take ~10000 known real\n",
    "# combine and take ~25% to put in holdout set - do not use to model - use as verifier of model\n",
    "# feature extraction - \n",
    "# can have 10 different metrics for exclamation marks: \n",
    "# total number of exclamation marks per \n",
    "# \n",
    "# look at number of key words: \"outrageous\", \"strong words\"\n",
    "# Q: how strong is the strongest word\n",
    "# unique word count - word frequency\n",
    "# columns: fake / not fake, trustworthiness of source, strength of strongest word found in given article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12999, 19)\n"
     ]
    }
   ],
   "source": [
    "# create new \"id\" column in df \n",
    "# reorder column names, setting \"id\" as first column and delete \"uuid\" col \n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "fake_df = fake_df[['site_url', 'domain_rank', 'author', 'published', 'title', 'thread_title', 'text', 'ord_in_thread', 'crawled', 'country', 'language', 'spam_score', 'main_img_url', 'replies_count', 'participants_count', 'likes', 'comments', 'shares', 'type']]\n",
    "print(fake_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count total number of exclamation marks in the given string\n",
    "def count_total_exclams(string):\n",
    "    exclam = '!'\n",
    "    num_exclams = string.count(exclam)\n",
    "    return num_exclams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the ratio of exclams to question marks + periods in the given string\n",
    "def exclam_ratio(string):\n",
    "    exclam = '!'\n",
    "    period = '.'\n",
    "    question = '?'\n",
    "    num_exclams = string.count(exclam)\n",
    "    num_period = string.count(period)\n",
    "    num_question = string.count(question)\n",
    "    if num_period + num_question == 0:\n",
    "        return num_exclams\n",
    "    return num_exclams / (num_period + num_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12987\n"
     ]
    }
   ],
   "source": [
    "# create new empty column for total_exclam_in_title count\n",
    "fake_df.assign(total_exclam_in_title=0)\n",
    "  \n",
    "# REMOVE ROWS THAT HAVE NAN thread_title\n",
    "\n",
    "fake_df = fake_df[fake_df['thread_title'].notnull()]\n",
    "print(len(fake_df))\n",
    "\n",
    "# correct id labels\n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    #title = fake_df.loc[i, 'title']\n",
    "    thread_title = fake_df.loc[i, 'thread_title']\n",
    "    count = count_total_exclams(thread_title)\n",
    "    fake_df.set_value(i, 'total_exclam_in_title', count)\n",
    "\n",
    "counts_by_title_exclams = fake_df.total_exclam_in_title.value_counts()\n",
    "# print(counts_by_title_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12941\n"
     ]
    }
   ],
   "source": [
    "# create new empty column for total_exclam_in_text count\n",
    "fake_df.assign(total_exclam_in_text=0)\n",
    "  \n",
    "# REMOVE ROWS THAT HAVE NAN thread_title\n",
    "fake_df = fake_df[fake_df['text'].notnull()]\n",
    "print(len(fake_df))\n",
    "\n",
    "# correct id labels\n",
    "fake_df['id'] = range(1, len(fake_df) + 1)\n",
    "fake_df = fake_df.set_index('id')\n",
    "\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    text = fake_df.loc[i, 'text']\n",
    "    count = count_total_exclams(text)\n",
    "    fake_df.set_value(i, 'total_exclam_in_text', count)\n",
    "\n",
    "counts_by_text_exclams = fake_df.total_exclam_in_text.value_counts()\n",
    "# print(counts_by_text_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new empty column for total_exclam_in_text count\n",
    "fake_df.assign(ratio_exclams_in_text=0)\n",
    "\n",
    "# compute the ratio of exclamation marks to other sentence terminating punctionation\n",
    "# and store in column \"ratio_exclams_in_text\"\n",
    "for i in range(1, len(fake_df) + 1):\n",
    "    text = fake_df.loc[i, 'text']\n",
    "    count = exclam_ratio(text)\n",
    "    fake_df.set_value(i, 'ratio_exclams_in_text', count)\n",
    "\n",
    "counts_ratio_exclams = fake_df.ratio_exclams_in_text.value_counts()\n",
    "# print(counts_ratio_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create series of total exclamation counts in each row's title\n",
    "# for index, row in df.iterrows():\n",
    "#     count = count_total_exclamation(row.title)\n",
    "#     print(count)\n",
    "#     df.loc[:,'total_crime'] = df.apply(get_total_crime, axis=1)\n",
    "#     df.loc[index, row.total_exclam_in_title] = count\n",
    "\n",
    "\n",
    "# df.loc[:, 'total_exclam_in_title'] = df.apply(count_total_exclams, axis=1)    \n",
    "# count_title_exclams = df['total_exclam_in_title'].value_counts()\n",
    "# print(count_title_exclams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make  copy of the fake_df containing only the thread_title & site_url\n",
    "sub_fake_df = fake_df[['thread_title', 'site_url']].copy()\n",
    "\n",
    "# replace all carriage returns and tabs with spaces\n",
    "for i in range(1, len(sub_fake_df) + 1):\n",
    "    title = sub_fake_df.loc[i, 'thread_title']\n",
    "    title = title.split(\"\\n\")\n",
    "    title = \" \".join(title)\n",
    "    title = title.split(\"\\t\")\n",
    "    title = \" \".join(title)\n",
    "    sub_fake_df.set_value(i, 'thread_title', title)\n",
    "\n",
    "# replace all carriage returns and tabs with spaces    \n",
    "for i in range(1, len(sub_fake_df) + 1):\n",
    "    url = sub_fake_df.loc[i, 'site_url']\n",
    "    url = url.split(\"\\n\")\n",
    "    url = \" \".join(url)\n",
    "    url = url.split(\"\\t\")\n",
    "    url = \" \".join(url)\n",
    "    sub_fake_df.set_value(i, 'site_url', url)\n",
    "    \n",
    "# print(sub_fake_df)\n",
    "\n",
    "# turn all tabs into spaces\n",
    "# x = \"The bananas are yellow and green\"\n",
    "# x = x.split(\" \")\n",
    "# print(x)\n",
    "# x = \"+\".join(x)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_real_df = real_df[['TITLE', 'URL']].copy()\n",
    "sub_real_df = sub_real_df.head(12941)\n",
    "\n",
    "# correct id labels\n",
    "sub_real_df['id'] = range(1, len(sub_real_df) + 1)\n",
    "sub_real_df = sub_real_df.set_index('id')\n",
    "\n",
    "# replace all carriage returns and tabs with spaces\n",
    "for i in range(1, len(sub_real_df) + 1):\n",
    "    title = sub_real_df.loc[i, 'TITLE']\n",
    "    title = title.split(\"\\n\")\n",
    "    title = \" \".join(title)\n",
    "    title = title.split(\"\\t\")\n",
    "    title = \" \".join(title)\n",
    "    sub_real_df.set_value(i, 'TITLE', title)\n",
    "\n",
    "# replace all carriage returns and tabs with spaces    \n",
    "for i in range(1, len(sub_real_df) + 1):\n",
    "    url = sub_real_df.loc[i, 'URL']\n",
    "    url = url.split(\"\\n\")\n",
    "    url = \" \".join(url)\n",
    "    url = url.split(\"\\t\")\n",
    "    url = \" \".join(url)\n",
    "    sub_real_df.set_value(i, 'URL', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   TITLE  \\\n",
      "id                                                         \n",
      "1      Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
      "2      Re: Why Did Attorney General Loretta Lynch Ple...   \n",
      "3      BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
      "4      PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
      "5      FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
      "6      Hillary Goes Absolutely Berserk On Protester A...   \n",
      "7      BREAKING! NYPD Ready To Make Arrests In Weiner...   \n",
      "8      WOW! WHISTLEBLOWER TELLS CHILLING STORY Of Mas...   \n",
      "9      BREAKING: CLINTON CLEARED...Was This A Coordin...   \n",
      "10     EVIL HILLARY SUPPORTERS Yell \"F*ck Trump\"…Burn...   \n",
      "11     YIKES! HILLARY GOES OFF THE RAILS…Pulls A Howa...   \n",
      "12     SAY GOODBYE! These 23 Hollywood Celebs Threate...   \n",
      "13     NOT KIDDING: Colleges Give Students “Safe Spac...   \n",
      "14     BOOM! MATH SHOWS Trump Would Have Beaten Obama...   \n",
      "15     BOOM! This Is How President Reagan Handled Pro...   \n",
      "16     TRUMP SUPPORTER GOT NUTS On MSNBC Reporter Cov...   \n",
      "17     TOMI LAHREN Has Special Message For Celebritie...   \n",
      "18     #BoycottComedian…ROBERT DENIRO Wanted “To Punc...   \n",
      "19     HE’S NEVER SOLD AN ORIGINAL PAINTING UNTIL NOW...   \n",
      "20     SORRY LIBERALS…You Can Stop With The Petitions...   \n",
      "21     MARK CUBAN: \"In The Event Donald Wins, I Have ...   \n",
      "22     TRUMP SUPPORTER Whose Brutal Beating By Black ...   \n",
      "23     WOW! WHITE Liberals Suggest Blacks Are Too Stu...   \n",
      "24     LOL! BRITISH WIFE Of LIB ACTOR Who Said: “Ther...   \n",
      "25     EPIC! TUCKER CARLSON Demolishes NYC Councilman...   \n",
      "26     FUNNY! SNL’S SOLUTION To Democrat Election Den...   \n",
      "27     DONALD TRUMP Calls Meeting With Press…Dresses ...   \n",
      "28     OOPS! CRYBABY HAMILTON STARS Who Lectured Penc...   \n",
      "29     WHITE TRUMP-BASHING LIB Reprimanded On LIVE CN...   \n",
      "30         BOOM! Kellyanne Conway Shuts Down CNN’s Cuomo   \n",
      "...                                                  ...   \n",
      "25853  US Navy SEALs board tanker hijacked in Libya -...   \n",
      "25854  UPDATE 2-US forces seize tanker carrying oil f...   \n",
      "25855  Norfolk-based destroyer to aid tanker seized b...   \n",
      "25856         US Navy SEALs board rogue Libya oil tanker   \n",
      "25857          U.S. forces seize control of rogue tanker   \n",
      "25858            US Navy SEALs seize fugitive oil tanker   \n",
      "25859  US Navy SEALs board tanker carrying oil from L...   \n",
      "25860  Shades of 'Captain Phillips': Navy SEALS retak...   \n",
      "25861      US Seals take control of rogue Libya oil ship   \n",
      "25862  US Navy SEALs seize stolen Libyan oil tanker h...   \n",
      "25863  Navy SEALs board and take control of oil tanke...   \n",
      "25864  US Special forces take control of rogue Libya ...   \n",
      "25865        Navy SEALs seize control of hijacked tanker   \n",
      "25866  US forces seize tanker carrying oil from Libya...   \n",
      "25867  US Navy Seals take control of rogue Libya oil ...   \n",
      "25868  US Seals take control of rogue Libya oil ship:...   \n",
      "25869  Navy SEALs board mystery tanker Morning Glory ...   \n",
      "25870  US Navy Seals retake hijacked oil tanker off t...   \n",
      "25871   Cyprus: SEALs take oil tanker from Libyan rebels   \n",
      "25872        US Navy Seals seize North Korean oil tanker   \n",
      "25873            Navy Seals board rogue Libya oil tanker   \n",
      "25874  US Navy Seal Commandos Seize North Korea Oil T...   \n",
      "25875  Israeli pair questioned over Pyongyang-bound o...   \n",
      "25876  Navy SEALs Board Oil Tanker Stolen From Libyan...   \n",
      "25877  US Seals take control of rogue Libya ship: Pen...   \n",
      "25878     Navy SEALS take control of hijacked oil tanker   \n",
      "25879  Navy SEALs take control of hijacked Libyan oil...   \n",
      "25880  U.S. Navy SEALs take control of North Korean-f...   \n",
      "25881  Oil tanker heading back to Libya after capture...   \n",
      "25882             US Seals storm 'oil theft' Libyan ship   \n",
      "\n",
      "                                                     URL  TARGET  \n",
      "id                                                                \n",
      "1                                    100percentfedup.com       1  \n",
      "2                                    100percentfedup.com       1  \n",
      "3                                    100percentfedup.com       1  \n",
      "4                                    100percentfedup.com       1  \n",
      "5                                    100percentfedup.com       1  \n",
      "6                                    100percentfedup.com       1  \n",
      "7                                    100percentfedup.com       1  \n",
      "8                                    100percentfedup.com       1  \n",
      "9                                    100percentfedup.com       1  \n",
      "10                                   100percentfedup.com       1  \n",
      "11                                   100percentfedup.com       1  \n",
      "12                                   100percentfedup.com       1  \n",
      "13                                   100percentfedup.com       1  \n",
      "14                                   100percentfedup.com       1  \n",
      "15                                   100percentfedup.com       1  \n",
      "16                                   100percentfedup.com       1  \n",
      "17                                   100percentfedup.com       1  \n",
      "18                                   100percentfedup.com       1  \n",
      "19                                   100percentfedup.com       1  \n",
      "20                                   100percentfedup.com       1  \n",
      "21                                   100percentfedup.com       1  \n",
      "22                                   100percentfedup.com       1  \n",
      "23                                   100percentfedup.com       1  \n",
      "24                                   100percentfedup.com       1  \n",
      "25                                   100percentfedup.com       1  \n",
      "26                                   100percentfedup.com       1  \n",
      "27                                   100percentfedup.com       1  \n",
      "28                                   100percentfedup.com       1  \n",
      "29                                   100percentfedup.com       1  \n",
      "30                                   100percentfedup.com       1  \n",
      "...                                                  ...     ...  \n",
      "25853  http://www.reuters.com/article/2014/03/17/usa-...       0  \n",
      "25854  http://www.reuters.com/article/2014/03/17/usa-...       0  \n",
      "25855  http://hamptonroads.com/2014/03/norfolkbased-d...       0  \n",
      "25856  http://www.aljazeera.com/news/africa/2014/03/u...       0  \n",
      "25857  http://www.ksdk.com/story/news/nation/2014/03/...       0  \n",
      "25858  http://www.latimes.com/world/worldnow/la-fg-wn...       0  \n",
      "25859  http://uk.reuters.com/article/2014/03/17/uk-us...       0  \n",
      "25860  http://www.arktimes.com/ArkansasBlog/archives/...       0  \n",
      "25861  http://www.ptinews.com/news/4509295_-US-Seals-...       0  \n",
      "25862  http://www.allvoices.com/contributed-news/1671...       0  \n",
      "25863  http://www.newser.com/article/a119b55666b54365...       0  \n",
      "25864  http://www.brisbanetimes.com.au/world/us-speci...       0  \n",
      "25865  http://www.abc17news.com/national-news/Navy-SE...       0  \n",
      "25866  http://www.worldbulletin.net/world/131244/us-f...       0  \n",
      "25867  http://news.yahoo.com/us-seals-control-rogue-l...       0  \n",
      "25868  http://www.ptinews.com/news/4509295_US-Seals-t...       0  \n",
      "25869  http://www.washingtonpost.com/news/morning-mix...       0  \n",
      "25870  http://www.rawstory.com/rs/2014/03/17/us-navy-...       0  \n",
      "25871  http://www.politico.com/story/2014/03/cyprus-n...       0  \n",
      "25872  http://voiceofrussia.com/news/2014_03_17/US-Na...       0  \n",
      "25873  http://blouinnews.com/78329/story/navy-seals-b...       0  \n",
      "25874  http://www.ibtimes.co.uk/us-navy-seal-commando...       0  \n",
      "25875  http://www.thestandard.com.hk/breaking_news_de...       0  \n",
      "25876  http://www.huffingtonpost.com/2014/03/17/navy-...       0  \n",
      "25877  http://www.ptinews.com/news/4509045_US-Seals-t...       0  \n",
      "25878  http://www.washingtontimes.com/news/2014/mar/1...       0  \n",
      "25879  http://wtkr.com/2014/03/17/navy-seals-take-con...       0  \n",
      "25880  http://www.dailymail.co.uk/news/article-258257...       0  \n",
      "25881  http://www.libyaherald.com/2014/03/17/oil-tank...       0  \n",
      "25882  http://www.upstreamonline.com/live/article1355...       0  \n",
      "\n",
      "[25882 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# create new column, 'TARGET' with 1 fake and 0 for real\n",
    "sub_fake_df['TARGET'] = 1\n",
    "sub_fake_df = sub_fake_df.rename(columns = {'thread_title':'TITLE', 'site_url':'URL'})\n",
    "sub_real_df['TARGET'] = 0\n",
    "\n",
    "# combine the two dataframes\n",
    "combined_df = sub_fake_df.append(sub_real_df)\n",
    "\n",
    "# reorder the id index of the combined_df set\n",
    "# correct id labels\n",
    "combined_df['id'] = range(1, len(combined_df) + 1)\n",
    "combined_df = combined_df.set_index('id')\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "combined_df = shuffle(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert combined_df into a new TAB DELIMITED csv\n",
    "combined_df.to_csv(\"cleaned_combined_dataset.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create two sets of data: first is TRAINING SET: 75% OF DATA, 25% VALIDATOR via random num generator\n",
    "sampler = np.random.rand(len(combined_df)) < 0.75\n",
    "training_set = combined_df[sampler]\n",
    "test_set = combined_df[~sampler]\n",
    "\n",
    "#print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set.to_csv(\"training_set.csv\", sep='\\t')\n",
    "test_set.to_csv(\"holdout_set.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-712a58a744c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ps' is not defined"
     ]
    }
   ],
   "source": [
    "# stem the \"fake news\" data\n",
    "fakeBlob = {} \n",
    "for i in range(len(sub_fake_df['TITLE'])):\n",
    "    try:\n",
    "        ss8 = str(sub_fake_df['TITLE'].iloc[i].encode('utf8'))\n",
    "    except:\n",
    "        pass\n",
    "    words = word_tokenize(ss8)\n",
    "    x = set()\n",
    "    for w in words:\n",
    "        x.add(ps.stem(w).lower())\n",
    "\n",
    "    for stword in x:\n",
    "        if stword in fakeBlob:\n",
    "            fakeBlob[stword] = fakeBlob[stword] + 1\n",
    "            #print(stword, \" \", fakeBlob[stword])\n",
    "        else:\n",
    "            fakeBlob.setdefault(stword,1)\n",
    "            #print(stword,\" \", fakeBlob[stword])\n",
    "            \n",
    "# print(fakeBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem the \"real news\" data    \n",
    "goodBlob = {}\n",
    "for i in range(len(sub_fake_df['TITLE'])):\n",
    "    try:\n",
    "        ss8 = str(sub_fake_df['TITLE'].iloc[i].encode('utf8'))\n",
    "    except:\n",
    "        pass\n",
    "    words = word_tokenize(ss8)\n",
    "    x = set()\n",
    "    for w in words:\n",
    "        x.add(ps.stem(w).lower())\n",
    "\n",
    "    for stword in x:\n",
    "        if stword in goodBlob:\n",
    "            goodBlob[stword] = goodBlob[stword] + 1\n",
    "            #print(stword, \" \", goodBlob[stword])\n",
    "        else:\n",
    "            goodBlob.setdefault(stword,1)\n",
    "            #print(stword,\" \", goodBlob[stword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "riskdict = {}\n",
    "for word in fakeBlob:\n",
    "    if word in goodBlob:\n",
    "        count = (fakeBlob[word] + goodBlob[word])\n",
    "    else:\n",
    "        count = fakeBlob[word]\n",
    "    if count >= 10:\n",
    "        riskdict[word] = fakeBlob[word] / count\n",
    "\n",
    "for word in goodBlob:\n",
    "    if word not in fakeBlob and goodBlob[word] > 10:\n",
    "        riskdict[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "riskword = \"\"\n",
    "for i in range(len(test_set['TITLE'])):\n",
    "    fakeaggregate = 0\n",
    "    goodaggregate = 0\n",
    "    riskyword = 0\n",
    "    safeword = 1\n",
    "    try:\n",
    "        ss8 = str(test_set['TITLE'].iloc[i].encode('utf8'))\n",
    "    except:\n",
    "        pass\n",
    "    words = word_tokenize(ss8)\n",
    "    x = set()\n",
    "    for w in words:\n",
    "        x.add(ps.stem(w).lower())\n",
    "\n",
    "    for stword in x:\n",
    "        if stword in riskdict:\n",
    "            if riskdict[stword] > riskyword:\n",
    "                riskword = riskdict[stword]\n",
    "            if riskdict[stword] < safeword:\n",
    "                safeword = riskdict[stword]\n",
    "\n",
    "        if stword in fakeBlob:\n",
    "            fakeaggregate = goodBlob[stword] + fakeaggregate\n",
    "\n",
    "        if stword in goodBlob:\n",
    "            goodaggregate = goodBlob[stword] + goodaggregate\n",
    "\n",
    "print(ss8,\"\\n\")\n",
    "print(fakeaggregate, \" \", goodaggregate, \" \", riskword, \" \", safeword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
